# ğŸ“˜ Fundamentos de Sistemas DistribuÃ­dos e ComunicaÃ§Ã£o em Rede

Este repositÃ³rio reÃºne uma explicaÃ§Ã£o teÃ³rica completa sobre **Sistemas DistribuÃ­dos**, **Escalabilidade**, **Clusters**, **Threads** e **ComunicaÃ§Ã£o entre Processos em Rede**.  
Todo o conteÃºdo foi preparado com rigor acadÃªmico, como seria apresentado em aulas de graduaÃ§Ã£o e pÃ³s-graduaÃ§Ã£o em CiÃªncia da ComputaÃ§Ã£o.

---

# ğŸ“Œ SumÃ¡rio

1. [O que sÃ£o Sistemas DistribuÃ­dos](#o-que-sÃ£o-sistemas-distribuÃ­dos)  
2. [Escalabilidade](#escalabilidade)  
   - Escalabilidade Vertical  
   - Escalabilidade Horizontal  
3. [Clusters](#clusters)  
4. [Threads](#threads)  
5. [PrincÃ­pios BÃ¡sicos da ComunicaÃ§Ã£o de Processos em Rede](#princÃ­pios-bÃ¡sicos-da-comunicaÃ§Ã£o-de-processos-em-rede)  
6. [Arquitetura em Camadas e Sockets](#arquitetura-em-camadas-e-sockets)  
7. [ConsistÃªncia, Tempo e Falhas](#consistÃªncia-tempo-e-falhas)  
8. [ConclusÃ£o](#conclusÃ£o)

---

# ğŸ§© O que sÃ£o Sistemas DistribuÃ­dos

Um **Sistema DistribuÃ­do** Ã© um conjunto de computadores independentes que, para o usuÃ¡rio final, se comportam como um Ãºnico sistema coerente.

Em outras palavras, vÃ¡rias mÃ¡quinas autÃ´nomas, conectadas por rede, cooperam para executar tarefas comuns e fornecer um serviÃ§o integrado.

### CaracterÃ­sticas centrais:

- NÃ£o existe memÃ³ria compartilhada entre mÃ¡quinas.  
- A comunicaÃ§Ã£o ocorre atravÃ©s de **troca de mensagens**.  
- Cada mÃ¡quina possui seu prÃ³prio sistema operacional, relÃ³gio e estado.  
- Falhas sÃ£o inevitÃ¡veis e devem ser tratadas como parte do modelo.  
- O sistema precisa fornecer transparÃªncia ao usuÃ¡rio (de falha, localizaÃ§Ã£o, concorrÃªncia etc.).

### ImportÃ¢ncia
Sistemas distribuÃ­dos sÃ£o a base da Internet moderna, computaÃ§Ã£o em nuvem, bancos de dados distribuÃ­dos, microserviÃ§os, jogos online e praticamente todos os serviÃ§os de larga escala.

---

# ğŸš€ Escalabilidade

Escalabilidade Ã© a capacidade de um sistema **aumentar seu desempenho**, **suportar mais usuÃ¡rios** ou **processar maiores volumes de dados** sem degradaÃ§Ã£o significativa.

Existem dois modelos principais:

---

## ğŸ”¼ Escalabilidade Vertical (Scale Up)

Consiste em **aumentar a capacidade de uma Ãºnica mÃ¡quina**.

Exemplos:
- mais CPU  
- mais RAM  
- SSD mais rÃ¡pido  
- processadores com mais nÃºcleos  

**Vantagem:** simples, nÃ£o exige mudar o software.  
**Desvantagem:** existe um limite fÃ­sico; se a mÃ¡quina falha, o sistema cai.

---

## ğŸ” Escalabilidade Horizontal (Scale Out)

Consiste em **adicionar mais mÃ¡quinas** para compartilhar o trabalho.

Ã‰ o modelo usado por Google, Amazon, Netflix e grandes sistemas distribuÃ­dos.

**Vantagens:**
- alta disponibilidade  
- escala praticamente ilimitada  
- redundÃ¢ncia de dados  
- tolerÃ¢ncia a falhas  

**Desafios teÃ³ricos:**
- coordenaÃ§Ã£o distribuÃ­da  
- sincronizaÃ§Ã£o  
- consistÃªncia  
- comunicaÃ§Ã£o por mensagens  

---

# ğŸ–¥ï¸ Clusters

Um **cluster** Ã© um conjunto de computadores independentes (nÃ³s) que trabalham juntos como se fossem um Ãºnico sistema.

Cada nÃ³ possui:
- seu prÃ³prio sistema operacional  
- sua prÃ³pria CPU  
- sua prÃ³pria memÃ³ria  
- sua prÃ³pria comunicaÃ§Ã£o  

### Tipos comuns de clusters:

#### ğŸ”¹ Cluster de Alto Desempenho (HPC)
Usados para cÃ¡lculos cientÃ­ficos e simulaÃ§Ãµes.

#### ğŸ”¹ Cluster de Alta Disponibilidade (HA)
Focados em nunca ficar offline; se um nÃ³ falha, outro assume.

#### ğŸ”¹ Cluster de Balanceamento de Carga
VÃ¡rios servidores dividem as requisiÃ§Ãµes de usuÃ¡rios.

#### ğŸ”¹ Cluster de Armazenamento DistribuÃ­do
Ex.: Hadoop HDFS, Google File System, Ceph.

Clusters sÃ£o a base da computaÃ§Ã£o moderna e tornam possÃ­vel a escalabilidade horizontal.

---

# ğŸ§µ Threads

Uma **thread** Ã© uma linha de execuÃ§Ã£o dentro de um processo.

Enquanto o cluster trabalha com mÃºltiplas mÃ¡quinas,
as threads trabalham com mÃºltiplos fluxos dentro da mesma mÃ¡quina.

### CaracterÃ­sticas:
- compartilham memÃ³ria  
- executam em paralelo se houver mÃºltiplos nÃºcleos  
- usadas para acelerar tarefas ou processar mÃºltiplas operaÃ§Ãµes simultÃ¢neas  

### Hierarquia completa:

### Como testar (threads)

  - No terminal A: python3 chat_server_threaded.py 0.0.0.0 25000
  -  Em N terminais diferentes: python3 chat_client.py 127.0.0.1 25000


---

# ğŸ”— PrincÃ­pios BÃ¡sicos da ComunicaÃ§Ã£o de Processos em Rede

Processos em mÃ¡quinas diferentes nÃ£o compartilham:
- memÃ³ria  
- relÃ³gio  
- sistema operacional  

Eles sÃ³ conseguem cooperar atravÃ©s de **mensagens enviadas pela rede**.

### Propriedades fundamentais:

#### ğŸ“¡ ComunicaÃ§Ã£o por mensagens
A Ãºnica forma de interaÃ§Ã£o entre processos distribuÃ­dos.

Problemas naturais:
- atraso variÃ¡vel  
- perda de pacotes  
- duplicaÃ§Ã£o  
- chegada fora de ordem  

#### ğŸ§  Estado isolado
Cada processo conhece apenas seu prÃ³prio estado e aquilo que recebe por mensagens.

#### â— Falhas sÃ£o parte do modelo
MÃ¡quinas podem:
- desligar  
- travar  
- enviar mensagens incorretas  
- falhar de forma bizantina  

---

# ğŸ›ï¸ Arquitetura em Camadas e Sockets

A comunicaÃ§Ã£o ocorre atravÃ©s da **arquitetura TCP/IP**, composta por cinco camadas:

1. **AplicaÃ§Ã£o** â€” HTTP, FTP, DNS  
2. **Transporte** â€” TCP, UDP  
3. **Rede** â€” IP  
4. **Enlace** â€” Ethernet, Wi-Fi  
5. **FÃ­sica** â€” transmissÃ£o dos bits

### ğŸ“¨ Sockets
Um **socket** Ã© a interface que conecta um processo Ã  rede.

Um socket Ã© identificado por:


Ã‰ o mecanismo usado pelas aplicaÃ§Ãµes para enviar e receber mensagens.

### ğŸ”„ Encapsulamento
Cada camada adiciona seu prÃ³prio cabeÃ§alho ao dado original.  
No destino, ocorre o **desencapsulamento**, camada por camada.

---

# â³ ConsistÃªncia, Tempo e Falhas

Sistemas distribuÃ­dos precisam lidar com desafios teÃ³ricos profundos:

### ğŸ•’ Tempo
NÃ£o existe relÃ³gio global perfeito.  
Surgem conceitos como:
- relÃ³gios lÃ³gicos (Lamport)  
- ordenaÃ§Ã£o parcial  
- causalidade entre eventos  

### ğŸ§© ConsistÃªncia
Garantir que todos os nÃ³s enxergam o mesmo estado Ã© difÃ­cil.  
Teoremas fundamentais:
- **CAP** â€” ConsistÃªncia, Disponibilidade, TolerÃ¢ncia a Particionamento  
- **FLP** â€” impossibilidade de consenso perfeito em sistemas assÃ­ncronos com falhas  

### âš ï¸ Falhas
Falhas sÃ£o inevitÃ¡veis:  
- falhas por parada  
- falhas de omissÃ£o  
- falhas temporÃ¡rias  
- falhas bizantinas  

Sistemas distribuÃ­dos precisam ser robustos o suficiente para continuar funcionando apesar delas.

---

# ğŸ§  ConclusÃ£o

Sistemas distribuÃ­dos sÃ£o o coraÃ§Ã£o da computaÃ§Ã£o moderna.  
Eles permitem conectar mÃ¡quinas independentes para construir serviÃ§os globais, escalÃ¡veis e resilientes.

Para tornÃ¡-los possÃ­veis, precisamos dominar:
- comunicaÃ§Ã£o por mensagens  
- escalabilidade horizontal  
- clusters  
- threads  
- protocolos e camadas  
- consistÃªncia e tolerÃ¢ncia a falhas  

Este documento serve como base teÃ³rica completa para entendimento desses sistemas.

---

# ğŸ“š LicenÃ§a

Este repositÃ³rio Ã© de uso educacional e aberto para estudos, melhorias e compartilhamento.

  
